name: Export JSON/XML/YAML/CSV/MYSQL/PSQL/SQLITE/SQLSERVER/MONGODB

on:
  push:
    branches:
      - master
    paths-ignore:
      - "**"
      - "!bin/Commands/Export**"
  workflow_dispatch:
    inputs:
      pass:
        description: "Passcode"
        required: true

jobs:
  export:
    name: JSON/XML/YAML/CSV/MYSQL/PSQL/SQLITE/SQLSERVER/MONGODB
    runs-on: ubuntu-24.04

    strategy:
      matrix:
        php-version: [8.2]
        node-version: [20.x]
      fail-fast: false

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: true
          ref: ${{ github.head_ref }}

      - name: Setup PHP
        uses: shivammathur/setup-php@v2
        with:
          php-version: ${{ matrix.php-version }}
          extensions: intl #optional
          coverage: none
          ini-values: "post_max_size=256M, memory_limit=512M" #optional

      - name: Use Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
          cache-dependency-path: nmig/package-lock.json

      - name: Cache Composer dependencies
        uses: actions/cache@v4
        with:
          path: bin/vendor
          key: ${{ runner.os }}-composer-${{ hashFiles('bin/composer.lock') }}
          restore-keys: ${{ runner.os }}-composer-

      - name: Start MySQL service
        run: |
          sudo systemctl start mysql.service
          mysql -V
          # Wait for MySQL to be ready
          while ! mysqladmin ping -h"127.0.0.1" --silent; do
            echo "Waiting for MySQL..."
            sleep 1
          done

      - name: Start PostgreSQL service
        run: |
          sudo systemctl start postgresql.service
          pg_isready
          pg_lsclusters
          sudo -u postgres psql -c "CREATE DATABASE world;"
          sudo -u postgres psql -c "ALTER USER postgres PASSWORD 'postgres';"
          sudo -u postgres psql -c "\l"

      - name: Setup MongoDB
        uses: supercharge/mongodb-github-action@1.10.0
        with:
          mongodb-version: '6.0'
          mongodb-replica-set: rs0

      - name: Install MongoDB Database Tools
        run: |
          # Download MongoDB Database Tools directly
          wget -q https://fastdl.mongodb.org/tools/db/mongodb-database-tools-ubuntu2204-x86_64-100.7.3.deb
          sudo dpkg -i mongodb-database-tools-ubuntu2204-x86_64-100.7.3.deb
          rm -rf mongodb-database-tools-ubuntu2204-x86_64-100.7.3.deb

          # Verify installation
          mongoimport --version

      - name: Build from Contributions
        run: |
          echo "üèóÔ∏è  Building database from contributions..."
          python3 bin/build_from_contributions.py
          echo "‚úÖ Build complete"

      - name: Generate SQL from JSON
        run: |
          echo "üìù Generating SQL files from JSON..."
          python3 bin/inject_json_to_mysql.py
          echo "‚úÖ SQL generation complete"

      - name: Combine SQL files into world.sql
        run: |
          echo "üì¶ Combining SQL files..."
          # Create header with DROP TABLE commands
          cat > sql/world.sql << 'EOF'
          -- -------------------------------------------------------------
          -- Generated from contributions/
          -- Combined world database
          -- -------------------------------------------------------------

          /*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
          /*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
          /*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
          /*!40101 SET NAMES utf8mb4 */;
          /*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
          /*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
          /*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
          /*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

          DROP TABLE IF EXISTS `cities`;
          DROP TABLE IF EXISTS `states`;
          DROP TABLE IF EXISTS `countries`;
          DROP TABLE IF EXISTS `subregions`;
          DROP TABLE IF EXISTS `regions`;

          EOF
          # Append all table SQL files (they already have CREATE TABLE and INSERT)
          cat sql/regions.sql sql/subregions.sql sql/countries.sql sql/states.sql sql/cities.sql >> sql/world.sql
          echo "‚úÖ world.sql created"

      - name: Setup MySQL DB
        run: |
          mysql -uroot -proot -e "CREATE DATABASE world CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;"
          mysql -uroot -proot -e "SHOW DATABASES;"
          mysql -uroot -proot --default-character-set=utf8mb4 world < sql/world.sql

      - name: Setup & Run NMIG (MySQL to PostgreSQL)
        run: |
          cp nmig.config.json nmig/config/config.json
          cd nmig
          npm install
          npm run build
          npm start
          cd ..

      - name: Setup MySQLtoSQLite
        run: |
          python -m pip install --upgrade pip
          pip install mysql-to-sqlite3
          mysql2sqlite --version

      - name: Setup variables
        run: |
          echo "region_count=$(mysql -uroot -proot -e 'SELECT COUNT(*) FROM world.regions;' -s)" >> $GITHUB_ENV
          echo "subregion_count=$(mysql -uroot -proot -e 'SELECT COUNT(*) FROM world.subregions;' -s)" >> $GITHUB_ENV
          echo "country_count=$(mysql -uroot -proot -e 'SELECT COUNT(*) FROM world.countries;' -s)" >> $GITHUB_ENV
          echo "state_count=$(mysql -uroot -proot -e 'SELECT COUNT(*) FROM world.states;' -s)" >> $GITHUB_ENV
          echo "city_count=$(mysql -uroot -proot -e 'SELECT COUNT(*) FROM world.cities;' -s)" >> $GITHUB_ENV
          echo "current_date=$(date +'%dth %b %Y')" >> $GITHUB_ENV

      - name: Composer Dependencies
        working-directory: ./bin
        run: |
          composer install
          php console list

      - name: Export JSON
        working-directory: ./bin
        run: php console export:json

      - name: Compress Large JSON Files
        run: |
          echo "üóúÔ∏è  Compressing large JSON files..."
          # Compress countries+states+cities.json (42MB - creates .json.gz)
          if [ -f json/countries+states+cities.json ]; then
            gzip -9 -k json/countries+states+cities.json
            ls -lh json/countries+states+cities.json.gz
          fi
          # Note: countries.json, states.json, cities.json are NOT compressed
          # as they are actively used by the build process
          echo "‚úÖ JSON compression complete"

      - name: Export XML
        working-directory: ./bin
        run: php console export:xml

      - name: Export YAML
        working-directory: ./bin
        run: php console export:yaml

      - name: Export CSV
        working-directory: ./bin
        run: php console export:csv

      - name: Export MySQL SQL
        run: |
          mkdir -p sql
          mysqldump -uroot -proot --single-transaction --add-drop-table --disable-keys --set-charset --skip-add-locks world regions > sql/regions.sql
          mysqldump -uroot -proot --single-transaction --add-drop-table --disable-keys --set-charset --skip-add-locks world subregions > sql/subregions.sql
          mysqldump -uroot -proot --single-transaction --add-drop-table --disable-keys --set-charset --skip-add-locks world countries > sql/countries.sql
          mysqldump -uroot -proot --single-transaction --add-drop-table --disable-keys --set-charset --skip-add-locks world states > sql/states.sql
          mysqldump -uroot -proot --single-transaction --add-drop-table --disable-keys --set-charset --skip-add-locks world cities > sql/cities.sql

      - name: Generate Schema Files
        run: |
          echo "üìã Generating schema files..."
          # Export MySQL schema only (no data)
          mysqldump -uroot -proot --no-data --single-transaction --add-drop-table world > sql/schema.sql
          # Also export for other formats
          mysqldump -uroot -proot --no-data --single-transaction --add-drop-table world > psql/schema.sql
          mysqldump -uroot -proot --no-data --single-transaction --add-drop-table world > sqlserver/schema.sql
          echo "‚úÖ Schema files generated"

      - name: Compress Large SQL Files
        run: |
          echo "üóúÔ∏è  Compressing large SQL files..."
          # Compress world.sql (creates world.sql.gz, keeps original)
          gzip -9 -k sql/world.sql
          # Compress cities.sql (creates cities.sql.gz, keeps original)
          gzip -9 -k sql/cities.sql
          # Show file sizes
          echo "Original files:"
          ls -lh sql/world.sql sql/cities.sql
          echo "Compressed files:"
          ls -lh sql/world.sql.gz sql/cities.sql.gz
          echo "‚úÖ Compression complete"

      - name: Export PostgreSQL SQL
        env:
          PGPASSWORD: postgres
        run: |
          mkdir -p psql
          pg_dump --dbname=postgresql://postgres:postgres@localhost/world -Fp --inserts --clean --if-exists -t regions > psql/regions.sql
          pg_dump --dbname=postgresql://postgres:postgres@localhost/world -Fp --inserts --clean --if-exists -t subregions > psql/subregions.sql
          pg_dump --dbname=postgresql://postgres:postgres@localhost/world -Fp --inserts --clean --if-exists -t countries > psql/countries.sql
          pg_dump --dbname=postgresql://postgres:postgres@localhost/world -Fp --inserts --clean --if-exists -t states > psql/states.sql
          pg_dump --dbname=postgresql://postgres:postgres@localhost/world -Fp --inserts --clean --if-exists -t cities > psql/cities.sql
          pg_dump --dbname=postgresql://postgres:postgres@localhost/world -Fp --inserts --clean --if-exists > psql/world.sql

      - name: Compress Large PostgreSQL Files
        run: |
          echo "üóúÔ∏è  Compressing large PostgreSQL files..."
          # Creates world.sql.gz and cities.sql.gz
          gzip -9 -k psql/world.sql
          gzip -9 -k psql/cities.sql
          echo "Compressed files:"
          ls -lh psql/world.sql.gz psql/cities.sql.gz
          echo "‚úÖ PostgreSQL compression complete"

      - name: Export SQLite
        run: |
          # Clean up any existing SQLite files first
          rm -rf sqlite/
          mkdir -p sqlite

          mysql2sqlite -d world -t regions --mysql-password root -u root -f sqlite/regions.sqlite3
          mysql2sqlite -d world -t subregions --mysql-password root -u root -f sqlite/subregions.sqlite3
          mysql2sqlite -d world -t countries --mysql-password root -u root -f sqlite/countries.sqlite3
          mysql2sqlite -d world -t states --mysql-password root -u root -f sqlite/states.sqlite3
          mysql2sqlite -d world -t cities --mysql-password root -u root -f sqlite/cities.sqlite3
          mysql2sqlite -d world --mysql-password root -u root -f sqlite/world.sqlite3

      - name: Compress Large SQLite Files
        run: |
          echo "üóúÔ∏è  Compressing large SQLite files..."
          # Compress world.sqlite3 (creates world.sqlite3.gz)
          gzip -9 -k sqlite/world.sqlite3
          # Compress cities.sqlite3 (creates cities.sqlite3.gz)
          gzip -9 -k sqlite/cities.sqlite3
          echo "Compressed files:"
          ls -lh sqlite/world.sqlite3.gz sqlite/cities.sqlite3.gz
          echo "‚úÖ SQLite compression complete"



      - name: Export SQL Server
        working-directory: ./bin
        run: php console export:sql-server

      - name: Compress Large SQL Server Files
        run: |
          echo "üóúÔ∏è  Compressing large SQL Server files..."
          # Creates world.sql.gz and cities.sql.gz
          if [ -f sqlserver/world.sql ]; then
            gzip -9 -k sqlserver/world.sql
            ls -lh sqlserver/world.sql.gz
          fi
          if [ -f sqlserver/cities.sql ]; then
            gzip -9 -k sqlserver/cities.sql
            ls -lh sqlserver/cities.sql.gz
          fi
          echo "‚úÖ SQL Server compression complete"

      - name: Export MongoDB
        working-directory: ./bin
        run: |
          php console export:mongodb
          ls -la ../mongodb

      - name: Import MongoDB
        working-directory: ./mongodb
        run: |
          # Wait for MongoDB to be ready
          sleep 5

          echo "Importing collections..."
          mongoimport --host localhost:27017 --db world --collection regions --file regions.json --jsonArray
          mongoimport --host localhost:27017 --db world --collection subregions --file subregions.json --jsonArray
          mongoimport --host localhost:27017 --db world --collection countries --file countries.json --jsonArray
          mongoimport --host localhost:27017 --db world --collection states --file states.json --jsonArray
          mongoimport --host localhost:27017 --db world --collection cities --file cities.json --jsonArray
          echo "Import completed"

          # Create a MongoDB dump
          mongodump --host localhost:27017 --db world --out mongodb-dump

          # Compress the dump
          tar -czvf world-mongodb-dump.tar.gz mongodb-dump
          echo "MongoDB dump created at mongodb/world-mongodb-dump.tar.gz"

          rm -rf mongodb-dump regions.json subregions.json countries.json states.json cities.json

      - name: Update README.md
        run: |
          sed -i "s/Total Regions : [0-9]* <br>/Total Regions : $region_count <br>/" README.md
          sed -i "s/Total Sub Regions : [0-9]* <br>/Total Sub Regions : $subregion_count <br>/" README.md
          sed -i "s/Total Countries : [0-9]* <br>/Total Countries : $country_count <br>/" README.md
          sed -i "s/Total States\/Regions\/Municipalities : [0-9]* <br>/Total States\/Regions\/Municipalities : $state_count <br>/" README.md
          sed -i "s/Total Cities\/Towns\/Districts : [0-9]* <br>/Total Cities\/Towns\/Districts : $city_count <br>/" README.md
          sed -i "s/Last Updated On : .*$/Last Updated On : $current_date/" README.md

      - name: Create Pull Request
        uses: peter-evans/create-pull-request@v7
        with:
          commit-message: |
            üì¶ Export database formats - ${{ env.current_date }}
            
            ‚úÖ All export formats completed successfully:
            - JSON/XML/YAML/CSV: Structured data exports
            - MySQL/PostgreSQL: SQL dump exports  
            - SQLite: Database file exports
            - SQL Server/MongoDB: Alternative format exports
            
            üìä Total records: ${{ env.country_count }} countries, ${{ env.state_count }} states, ${{ env.city_count }} cities
          committer: Darshan Gada <gadadarshan@gmail.com>
          signoff: true
          branch: export/Files
          delete-branch: true
          title: "üöÄ Database Export - ${{ env.current_date }}"
          body: |
            ## üì¶ Database Export Success
            
            All export formats have been successfully generated.
            
            ### üìä Data Statistics
            - **Regions**: ${{ env.region_count }}
            - **Subregions**: ${{ env.subregion_count }}  
            - **Countries**: ${{ env.country_count }}
            - **States**: ${{ env.state_count }}
            - **Cities**: ${{ env.city_count }}
            
            ### ‚úÖ Generated Formats
            - **JSON** - Structured data format
            - **XML** - Markup language format  
            - **YAML** - Human-readable format
            - **CSV** - Spreadsheet format
            - **MySQL** - Database dumps
            - **PostgreSQL** - Database dumps  
            - **SQLite** - Portable databases
            - **SQL Server** - T-SQL scripts
            - **MongoDB** - Collections + dump
            
            ---
            *Generated automatically by GitHub Actions*
          labels: |
            exports
            automated
          reviewers: dr5hn
