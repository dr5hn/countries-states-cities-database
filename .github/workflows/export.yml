name: Export JSON/XML/YAML/CSV/MYSQL/PSQL/SQLITE/SQLSERVER/MONGODB

on:
  push:
    branches:
      - master
    paths-ignore:
      - "**"
      - "!bin/Commands/Export**"
  workflow_dispatch:
    inputs:
      pass:
        description: "Passcode"
        required: true

jobs:
  export:
    name: JSON/XML/YAML/CSV/MYSQL/PSQL/SQLITE/SQLSERVER/MONGODB
    runs-on: ubuntu-24.04

    strategy:
      matrix:
        php-version: [8.2]
        node-version: [20.x]
      fail-fast: false

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: true
          ref: ${{ github.head_ref }}

      - name: Setup PHP
        uses: shivammathur/setup-php@v2
        with:
          php-version: ${{ matrix.php-version }}
          extensions: intl #optional
          coverage: none
          ini-values: "post_max_size=256M, memory_limit=512M" #optional

      - name: Use Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'
          cache-dependency-path: nmig/package-lock.json

      - name: Cache Composer dependencies
        uses: actions/cache@v4
        with:
          path: bin/vendor
          key: ${{ runner.os }}-composer-${{ hashFiles('bin/composer.lock') }}
          restore-keys: ${{ runner.os }}-composer-

      - name: Start MySQL service
        run: |
          sudo systemctl start mysql.service
          mysql -V
          # Wait for MySQL to be ready
          while ! mysqladmin ping -h"127.0.0.1" --silent; do
            echo "Waiting for MySQL..."
            sleep 1
          done

      - name: Start PostgreSQL service
        run: |
          sudo systemctl start postgresql.service
          pg_isready
          pg_lsclusters
          sudo -u postgres psql -c "CREATE DATABASE world;"
          sudo -u postgres psql -c "ALTER USER postgres PASSWORD 'postgres';"
          sudo -u postgres psql -c "\l"

      - name: Setup MongoDB
        uses: supercharge/mongodb-github-action@1.10.0
        with:
          mongodb-version: '6.0'
          mongodb-replica-set: rs0

      - name: Install MongoDB Database Tools
        run: |
          # Download MongoDB Database Tools directly
          wget -q https://fastdl.mongodb.org/tools/db/mongodb-database-tools-ubuntu2204-x86_64-100.7.3.deb
          sudo dpkg -i mongodb-database-tools-ubuntu2204-x86_64-100.7.3.deb
          rm -rf mongodb-database-tools-ubuntu2204-x86_64-100.7.3.deb

          # Verify installation
          mongoimport --version

      - name: Setup MySQL DB
        run: |
          echo "üóÑÔ∏è  Creating MySQL database..."
          mysql -uroot -proot -e "CREATE DATABASE world CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;"
          mysql -uroot -proot -e "SHOW DATABASES;"
          echo "‚úÖ Database created"

      - name: Initialize Database Schema
        run: |
          echo "üìã Creating database tables..."
          mysql -uroot -proot world < bin/db/schema.sql
          echo "‚úÖ Schema initialized - verifying tables..."
          mysql -uroot -proot -e "USE world; SHOW TABLES;"
          mysql -uroot -proot -e "USE world; SHOW CREATE TABLE regions\G" | head -20
          echo "‚úÖ All tables created successfully"

      - name: Setup Python Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install mysql-connector-python
          echo "‚úÖ Python dependencies installed"

      - name: Import JSON to MySQL
        run: |
          echo "üì• Importing contributions to MySQL..."
          python3 bin/scripts/sync/import_json_to_mysql.py --host localhost --user root --password root --database world
          echo "‚úÖ Import complete - IDs auto-assigned by MySQL"

      - name: Setup & Run NMIG (MySQL to PostgreSQL)
        run: |
          cp nmig.config.json nmig/config/config.json
          cd nmig
          npm install
          npm run build
          npm start
          cd ..

      - name: Setup MySQLtoSQLite
        run: |
          python -m pip install --upgrade pip
          pip install mysql-to-sqlite3
          mysql2sqlite --version

      - name: Setup variables
        run: |
          echo "region_count=$(mysql -uroot -proot -e 'SELECT COUNT(*) FROM world.regions;' -s)" >> $GITHUB_ENV
          echo "subregion_count=$(mysql -uroot -proot -e 'SELECT COUNT(*) FROM world.subregions;' -s)" >> $GITHUB_ENV
          echo "country_count=$(mysql -uroot -proot -e 'SELECT COUNT(*) FROM world.countries;' -s)" >> $GITHUB_ENV
          echo "state_count=$(mysql -uroot -proot -e 'SELECT COUNT(*) FROM world.states;' -s)" >> $GITHUB_ENV
          echo "city_count=$(mysql -uroot -proot -e 'SELECT COUNT(*) FROM world.cities;' -s)" >> $GITHUB_ENV
          echo "current_date=$(date +'%dth %b %Y')" >> $GITHUB_ENV

      - name: Composer Dependencies
        working-directory: ./bin
        run: |
          composer install
          php console list

      - name: Export JSON
        working-directory: ./bin
        run: php console export:json

      - name: Compress Large JSON Files
        run: |
          echo "üóúÔ∏è  Compressing large JSON files..."
          # Compress countries+states+cities.json (creates .json.gz)
          if [ -f json/countries+states+cities.json ]; then
            gzip -9 -k json/countries+states+cities.json
            ls -lh json/countries+states+cities.json.gz
          fi
          # Compress cities.json (160MB - too large for GitHub)
          if [ -f json/cities.json ]; then
            gzip -9 -k json/cities.json
            ls -lh json/cities.json.gz
          fi
          echo "‚úÖ JSON compression complete"

      - name: Export XML
        working-directory: ./bin
        run: php console export:xml

      - name: Compress Large XML Files
        run: |
          echo "üóúÔ∏è  Compressing large XML files..."
          # Compress cities.xml (151MB - too large for GitHub)
          if [ -f xml/cities.xml ]; then
            gzip -9 -k xml/cities.xml
            ls -lh xml/cities.xml.gz
          fi
          echo "‚úÖ XML compression complete"

      - name: Export YAML
        working-directory: ./bin
        run: php console export:yaml

      - name: Compress Large YAML Files
        run: |
          echo "üóúÔ∏è  Compressing large YAML files..."
          # Compress cities.yml (114MB - too large for GitHub)
          if [ -f yml/cities.yml ]; then
            gzip -9 -k yml/cities.yml
            ls -lh yml/cities.yml.gz
          fi
          echo "‚úÖ YAML compression complete"

      - name: Export CSV
        working-directory: ./bin
        run: php console export:csv

      - name: Compress Large CSV Files
        run: |
          echo "üóúÔ∏è  Compressing large CSV files..."
          # Compress translations.csv (large due to normalization of all translations)
          if [ -f csv/translations.csv ]; then
            gzip -9 -k csv/translations.csv
            ls -lh csv/translations.csv.gz
          fi
          echo "‚úÖ CSV compression complete"

      - name: Export MySQL SQL
        run: |
          mkdir -p sql
          mysqldump -uroot -proot --single-transaction --add-drop-table --disable-keys --set-charset --skip-add-locks world regions > sql/regions.sql
          mysqldump -uroot -proot --single-transaction --add-drop-table --disable-keys --set-charset --skip-add-locks world subregions > sql/subregions.sql
          mysqldump -uroot -proot --single-transaction --add-drop-table --disable-keys --set-charset --skip-add-locks world countries > sql/countries.sql
          mysqldump -uroot -proot --single-transaction --add-drop-table --disable-keys --set-charset --skip-add-locks world states > sql/states.sql
          mysqldump -uroot -proot --single-transaction --add-drop-table --disable-keys --set-charset --skip-add-locks world cities > sql/cities.sql
          # Export complete world database
          mysqldump -uroot -proot --single-transaction --add-drop-table --disable-keys --set-charset --skip-add-locks world > sql/world.sql

      - name: Add DROP TABLE commands to world.sql
        run: |
          echo "üßπ Adding DROP TABLE commands in correct order..."
          # Remove any existing DROP TABLE commands
          grep -v "DROP TABLE" sql/world.sql > sql/world_temp.sql
          # Create new file with DROP TABLE commands in correct order (reverse of foreign key dependencies)
          cat > sql/world.sql << 'EOF'
          -- -------------------------------------------------------------
          -- Generated from MySQL database
          -- Combined world database
          -- -------------------------------------------------------------

          DROP TABLE IF EXISTS `cities`;
          DROP TABLE IF EXISTS `states`;
          DROP TABLE IF EXISTS `countries`;
          DROP TABLE IF EXISTS `subregions`;
          DROP TABLE IF EXISTS `regions`;

          EOF
          # Append the dump without DROP TABLE commands
          cat sql/world_temp.sql >> sql/world.sql
          rm sql/world_temp.sql
          echo "‚úÖ DROP TABLE commands added"

      - name: Generate Schema Files
        run: |
          echo "üìã Generating schema files..."
          # Export MySQL schema only (no data)
          mysqldump -uroot -proot --no-data --single-transaction --add-drop-table world > sql/schema.sql
          # Also export for other formats
          mysqldump -uroot -proot --no-data --single-transaction --add-drop-table world > psql/schema.sql
          mysqldump -uroot -proot --no-data --single-transaction --add-drop-table world > sqlserver/schema.sql
          echo "‚úÖ Schema files generated"

      - name: Compress Large SQL Files
        run: |
          echo "üóúÔ∏è  Compressing large SQL files..."
          # Compress world.sql (creates world.sql.gz, keeps original)
          gzip -9 -k sql/world.sql
          # Compress cities.sql (creates cities.sql.gz, keeps original)
          gzip -9 -k sql/cities.sql
          # Show file sizes
          echo "Original files:"
          ls -lh sql/world.sql sql/cities.sql
          echo "Compressed files:"
          ls -lh sql/world.sql.gz sql/cities.sql.gz
          echo "‚úÖ Compression complete"

      - name: Export PostgreSQL SQL
        env:
          PGPASSWORD: postgres
        run: |
          mkdir -p psql
          pg_dump --dbname=postgresql://postgres:postgres@localhost/world -Fp --inserts --clean --if-exists -t regions > psql/regions.sql
          pg_dump --dbname=postgresql://postgres:postgres@localhost/world -Fp --inserts --clean --if-exists -t subregions > psql/subregions.sql
          pg_dump --dbname=postgresql://postgres:postgres@localhost/world -Fp --inserts --clean --if-exists -t countries > psql/countries.sql
          pg_dump --dbname=postgresql://postgres:postgres@localhost/world -Fp --inserts --clean --if-exists -t states > psql/states.sql
          pg_dump --dbname=postgresql://postgres:postgres@localhost/world -Fp --inserts --clean --if-exists -t cities > psql/cities.sql
          pg_dump --dbname=postgresql://postgres:postgres@localhost/world -Fp --inserts --clean --if-exists > psql/world.sql

      - name: Compress Large PostgreSQL Files
        run: |
          echo "üóúÔ∏è  Compressing large PostgreSQL files..."
          # Creates world.sql.gz and cities.sql.gz
          gzip -9 -k psql/world.sql
          gzip -9 -k psql/cities.sql
          echo "Compressed files:"
          ls -lh psql/world.sql.gz psql/cities.sql.gz
          echo "‚úÖ PostgreSQL compression complete"

      - name: Export SQLite
        run: |
          # Clean up any existing SQLite files first
          rm -rf sqlite/
          mkdir -p sqlite

          mysql2sqlite -d world -t regions --mysql-password root -u root -f sqlite/regions.sqlite3
          mysql2sqlite -d world -t subregions --mysql-password root -u root -f sqlite/subregions.sqlite3
          mysql2sqlite -d world -t countries --mysql-password root -u root -f sqlite/countries.sqlite3
          mysql2sqlite -d world -t states --mysql-password root -u root -f sqlite/states.sqlite3
          mysql2sqlite -d world -t cities --mysql-password root -u root -f sqlite/cities.sqlite3
          mysql2sqlite -d world --mysql-password root -u root -f sqlite/world.sqlite3

      - name: Compress Large SQLite Files
        run: |
          echo "üóúÔ∏è  Compressing large SQLite files..."
          # Compress world.sqlite3 (creates world.sqlite3.gz)
          gzip -9 -k sqlite/world.sqlite3
          # Compress cities.sqlite3 (creates cities.sqlite3.gz)
          gzip -9 -k sqlite/cities.sqlite3
          echo "Compressed files:"
          ls -lh sqlite/world.sqlite3.gz sqlite/cities.sqlite3.gz
          echo "‚úÖ SQLite compression complete"



      - name: Export SQL Server
        working-directory: ./bin
        run: php console export:sql-server

      - name: Compress Large SQL Server Files
        run: |
          echo "üóúÔ∏è  Compressing large SQL Server files..."
          # Creates world.sql.gz and cities.sql.gz
          if [ -f sqlserver/world.sql ]; then
            gzip -9 -k sqlserver/world.sql
            ls -lh sqlserver/world.sql.gz
          fi
          if [ -f sqlserver/cities.sql ]; then
            gzip -9 -k sqlserver/cities.sql
            ls -lh sqlserver/cities.sql.gz
          fi
          echo "‚úÖ SQL Server compression complete"

      - name: Export MongoDB
        working-directory: ./bin
        run: |
          php console export:mongodb
          ls -la ../mongodb

      - name: Import MongoDB
        working-directory: ./mongodb
        run: |
          # Wait for MongoDB to be ready
          sleep 5

          echo "Importing collections..."
          mongoimport --host localhost:27017 --db world --collection regions --file regions.json --jsonArray
          mongoimport --host localhost:27017 --db world --collection subregions --file subregions.json --jsonArray
          mongoimport --host localhost:27017 --db world --collection countries --file countries.json --jsonArray
          mongoimport --host localhost:27017 --db world --collection states --file states.json --jsonArray
          mongoimport --host localhost:27017 --db world --collection cities --file cities.json --jsonArray
          echo "Import completed"

          # Create a MongoDB dump
          mongodump --host localhost:27017 --db world --out mongodb-dump

          # Compress the dump
          tar -czvf world-mongodb-dump.tar.gz mongodb-dump
          echo "MongoDB dump created at mongodb/world-mongodb-dump.tar.gz"

          rm -rf mongodb-dump regions.json subregions.json countries.json states.json cities.json

      - name: Update README.md
        run: |
          sed -i "s/Total Regions : [0-9]* <br>/Total Regions : $region_count <br>/" README.md
          sed -i "s/Total Sub Regions : [0-9]* <br>/Total Sub Regions : $subregion_count <br>/" README.md
          sed -i "s/Total Countries : [0-9]* <br>/Total Countries : $country_count <br>/" README.md
          sed -i "s/Total States\/Regions\/Municipalities : [0-9]* <br>/Total States\/Regions\/Municipalities : $state_count <br>/" README.md
          sed -i "s/Total Cities\/Towns\/Districts : [0-9]* <br>/Total Cities\/Towns\/Districts : $city_count <br>/" README.md
          sed -i "s/Last Updated On : .*$/Last Updated On : $current_date/" README.md

      - name: Create Pull Request
        uses: peter-evans/create-pull-request@v7
        with:
          commit-message: |
            üì¶ Export database formats - ${{ env.current_date }}

            ‚úÖ All export formats completed successfully:
            - JSON/XML/YAML/CSV: Structured data exports
            - MySQL/PostgreSQL: SQL dump exports
            - SQLite: Database file exports
            - SQL Server/MongoDB: Alternative format exports

            üìä Total records: ${{ env.country_count }} countries, ${{ env.state_count }} states, ${{ env.city_count }} cities
          committer: Darshan Gada <gadadarshan@gmail.com>
          signoff: true
          branch: export/Files
          delete-branch: true
          title: "üöÄ Database Export - ${{ env.current_date }}"
          body: |
            ## üì¶ Database Export Success

            All export formats have been successfully generated.

            ### üìä Data Statistics
            - **Regions**: ${{ env.region_count }}
            - **Subregions**: ${{ env.subregion_count }}
            - **Countries**: ${{ env.country_count }}
            - **States**: ${{ env.state_count }}
            - **Cities**: ${{ env.city_count }}

            ### ‚úÖ Generated Formats
            - **JSON** - Structured data format
            - **XML** - Markup language format
            - **YAML** - Human-readable format
            - **CSV** - Spreadsheet format
            - **MySQL** - Database dumps
            - **PostgreSQL** - Database dumps
            - **SQLite** - Portable databases
            - **SQL Server** - T-SQL scripts
            - **MongoDB** - Collections + dump

            ---
            *Generated automatically by GitHub Actions*
          labels: |
            exports
            automated
          reviewers: dr5hn
